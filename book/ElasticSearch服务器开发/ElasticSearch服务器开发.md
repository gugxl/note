# 第一章 Elastic集群入门

## 1.1 全文检索

### 1.1.1 Lucene词汇表和架构
**文档**(document): 索引和搜索时使用的主要数据载体,包含一个或多个存在数据的字段
**字段**(field): 文档的一部分,包含名称和值两部分
**词**(term): 一个搜索单元,表示文件中的一个词
**标记/词元**(token): 表示在字段文本中出现的词,由这个词的文本、开始和结束偏移量以及类型组成.

**倒排索引**

索引额外文件包含了词向量(term vector)、文档值(doc value).

每个索引分为多个"写一次、读多次(write once and read many time)"的段(segment).建立索引时,一个段写入磁盘后就不能再更新.因此被删除的文档信息存储在
一个单独的文件中, 单该段自身不能被更新.

然而多个段可以通过**段合并(segment merge)**合并在一起.当强制段合并或者Lucene决定合并时,这些小段就会由Lucene合并成更大的一些段.合并需要I/O.
在合并时,不在需要的信息会被删除(例如,被删除的文档).除此之外,检索大段必检索存在相同数据的多个小段的速度更快.在一般情况下,搜索只需要将查询词与那些
编入索引的词相匹配.通过多个小段寻找和合并结果,显然会比让一个大段直接提供结果慢的多.

### 1.1.2 输入数据分析

输入的文档和查询的文本都要转换成可以被搜索的词.这个转换过程称为**分析**.这个过程我们一般需求会要经过语言分析处理,使得car和cars在索引中被视为是一个,
另外以往一些字段只用空格或者小写进行划分.

分析的工作有**分析器**完成,它由零到多个字符过滤器(Char Filters)加上一个分词器(Tokenizer)和零到多个标记过滤器(Token Filters)组成.

原始文本 -> 字符过滤器(Char Filters) -> 分词器(Tokenizer) -> 标记过滤器(Token Filters) -> 标记流(Token Stream)

常见的过滤器
1. **小写过滤器(lowercase filter)**: 将所有输入的词转换为小写.
2. **同义词过滤器(synonyms filter)**: 基于基本的同义词规则,把一个标记换成另外一个同义的标记. 
3. **多语言词干提取过滤器(multiple language stemming filter)**:减小标记(实际上是标记中的文本部分),得到词根或者基本形式,即词干.

过滤器是一个接一个处理的的,所以我们通过使用多个过滤器,可以拓展分析的可能性.

#### 索引和查询
建立索引时,Lucene会使用你选择的分析器来处理你的文档内容.不同的字段可以使用不同的分析器,所以文档的名称字段可以和汇总字段做不通的分析.也可以不分析字段.

查询时,查询将被分析.但是也可以选择不分析.例如前缀和词查询不被分析,匹配查询被分析.可以在被分析和查询和不被分析查询两者中选择非常有用.例如我么查询LightRed
这个词,标准分析器分析这个查询后,会去查询light和red,如果我们使用不经分析的查询类型,则会明确的查询LightRed这个词.

在索引和查询分析中,索引应该和查询次匹配.如果不匹配,Lucene不会返回所需的文档.例如在建立索引的时候使用了词干提取和小写,那你应该保证查询中的词也必须是词干和小写、
否则,Lucene将不会返回任何结果..重要的是在索引和查询分析时,对所用的标记过滤器保持相同的顺序,这样分析出来的词也是一样的.

### 1.1.3 评分和查询相关性
评分(scoring),是根据文档和查询的匹配度用计分工时计算的结果.默认情况下Lucene使用TF/IDF(term frequency/inverse document frequency, 词频/逆向文档频率)
评分机制.也会有其他评分办法. 评分越高,文档越相关.

## 1.2 ElasticSearch基础

### 1.2.1 数据架构的主要概念

#### 1. 索引
索引(index)是Elasticsearch对逻辑数据的逻辑存储,所以他可以分为更小的部分.可以把索引 看成关系数据库中的表.但是索引中的结果是为了快速有效的全文索引准备的,
它不存储原始值[注意:原书描述是错误的].(默认_source是开启的,存储的是原始值,但是可以关闭)

> 关闭_source影响
> 1. 不能使用_reindex写入新索引 
> 2. 不能使用_update和script update
> 3. 不能使用 _get 或 fields: _source 获取完整文档
> 4. 不能支持高亮（highlight）默认行为
> 5. 无法使用 _source 过滤返回字段
> 6. 不能使用 painless 脚本引用 ctx._source

#### 2. 文档
存储在Elasticsearch中的主要实体叫文档(document) 。类比与关系数据库中的一行记录,在Elasticsearch中,相同的**字段**必须是相同的类型,否则会报错.
> 如果我们不指定字段的类型,那么这个值第一次来的时候会进行推断,作为这个字段的类型,如果后续数据跟当前的不一致的会报错.
> 如果之前没有某个字段,后续插入的时候新出现了字段,默认情况下是会自动推断类型并且不报错的,但是我们关闭了 动态映射关闭（dynamic: false）就会报错
> 一种比较好的习惯是我们主动定义mapping,对于不确定的字段可以使用text或keyword 或者使用dynamic_templates

文档由多个字段组成,每个字段可能多次出现在一个文档中,这样的字段叫**多值字段(multivalued)**.每个字段都有类型,如文本、数值、日期.也可以是复杂类型,

#### 3. 文档类型 已经废弃

#### 4. 映射
主要是描述输入文本的内容格式， 定义了Elasticsearch怎么处理这些字段

### 1.2.2 Elasticsearch 主要概念

1. 节点和集群
Elasticsearch可以作为单个节点运行，也可以运行多个相互协作的服务器上。这些服务器称为集群（cluster），形成集群的每个服务器称为节点（node）

2. 分片
当有大量文档的时候，由于内存的限制、硬盘的能力、处理能力的不足、无法足够快的响应客户端请求。这种情况下，数据可以分为比较小的分片（shard）的部分
（每个分片都是一个独立的 apache Lucene索引）。每个分片可以存放在不同的服务器上，因此数据可以在集群中的节点传播。当查询的数据分布在不同的节点上，
Elasticsearch会把查询发送给每个相关的分片，并将结果合并到一起，而应用程序不知道分片的存在。此外多个分片可以加快索引。
3. 副本
为了提高查询的吞吐量或实现高可用，可以使用分片副本。副本（replica）只是一个分片的精确复制，每个分片可以有零个或多个副本。elasticsearch会有
很多相同的分片，其中的一个被选择为主分片（primary shard），复制更改索引操作，其余的为副本分片（replica shard）。在主分片丢失时，，例如所在的
服务器不可用的时候，集群将副本提升为新的主分片。

### 1.2.3 索引的建立和搜索

elasticsearch会帮我们找到对应的索引处理请求
![elasticsearch处理索引请求](./images/elasticsearch处理索引请求.png)
发送一个新文档给集群的时候，你指定一个目标索引并发送他给任意一个节点。这个节点知道目标索引有多少个分片，并且知道那个分片用来存储你的文档。
Elasticsearch使用文档的唯一标识符，来计算文档应该放到哪一个分片中。索引请求发送到一个节点后，该节点会转发文档到持有相关分片的目标节点中。

elasticsearch执行搜索请求
![elasticsearch执行搜索请求](./images/elasticsearch执行搜索请求.png)

尝试使用文档标识获取文档时，发送查询到一个节点，该节点使用同样的路由算法来决定持有文档的节点和分片，然后转发查询，获取结果，并把结果转发给你。
查询的过程更为复杂。除非使用了路由，查询将直接转发到单个分片，否则，收到查询请求的节点会把查询转发给保存了属于给定索引分片的所有节点，并要求
与查询匹配的文档的最少信息（默认情况下时标识符和得分）。这个阶段称为发散阶段（scatter phase）。收到这些信息后，该聚合节点（收到客户端请求的节点）
对结果进行排序，并发送第二个请求来获取结果列表的所需的文档（除标识符和得分以外其他的全部信息）。这个阶段称为收集阶段（gather phase）。这个阶段
完成后，把数据返回给客户端。
    
## 1.3 安装并配置集群
不再赘述

目录作用说明

｜ 目录 ｜ 描述 ｜
｜ ---- ｜ ----- ｜
｜ bin ｜ 运行elasticsearch实例和插件管理所需要的脚本 ｜
｜ config ｜ 配置目录 ｜ 
｜ lib ｜ Elasticsearch 使用的库 ｜
｜ data ｜ 数据存储目录 ｜
｜ logs ｜ 事件和错误记录的目录 ｜
｜ plugins ｜ 存储安装插件的目录 ｜
｜ work  ｜ 临时文件路径 ｜


### 1.4.3 新建文档