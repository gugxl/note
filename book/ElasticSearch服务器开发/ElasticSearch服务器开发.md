# 第一章 Elastic集群入门

## 1.1 全文检索

### 1.1.1 Lucene词汇表和架构
**文档**(document): 索引和搜索时使用的主要数据载体,包含一个或多个存在数据的字段
**字段**(field): 文档的一部分,包含名称和值两部分
**词**(term): 一个搜索单元,表示文件中的一个词
**标记/词元**(token): 表示在字段文本中出现的词,由这个词的文本、开始和结束偏移量以及类型组成.

**倒排索引**

索引额外文件包含了词向量(term vector)、文档值(doc value).

每个索引分为多个"写一次、读多次(write once and read many time)"的段(segment).建立索引时,一个段写入磁盘后就不能再更新.因此被删除的文档信息存储在
一个单独的文件中, 单该段自身不能被更新.

然而多个段可以通过**段合并(segment merge)**合并在一起.当强制段合并或者Lucene决定合并时,这些小段就会由Lucene合并成更大的一些段.合并需要I/O.
在合并时,不在需要的信息会被删除(例如,被删除的文档).除此之外,检索大段必检索存在相同数据的多个小段的速度更快.在一般情况下,搜索只需要将查询词与那些
编入索引的词相匹配.通过多个小段寻找和合并结果,显然会比让一个大段直接提供结果慢的多.

### 1.1.2 输入数据分析

输入的文档和查询的文本都要转换成可以被搜索的词.这个转换过程称为**分析**.这个过程我们一般需求会要经过语言分析处理,使得car和cars在索引中被视为是一个,
另外以往一些字段只用空格或者小写进行划分.

分析的工作有**分析器**完成,它由零到多个字符过滤器(Char Filters)加上一个分词器(Tokenizer)和零到多个标记过滤器(Token Filters)组成.

原始文本 -> 字符过滤器(Char Filters) -> 分词器(Tokenizer) -> 标记过滤器(Token Filters) -> 标记流(Token Stream)

常见的过滤器
1. **小写过滤器(lowercase filter)**: 将所有输入的词转换为小写.
2. **同义词过滤器(synonyms filter)**: 基于基本的同义词规则,把一个标记换成另外一个同义的标记. 
3. **多语言词干提取过滤器(multiple language stemming filter)**:减小标记(实际上是标记中的文本部分),得到词根或者基本形式,即词干.

过滤器是一个接一个处理的的,所以我们通过使用多个过滤器,可以拓展分析的可能性.

#### 索引和查询
建立索引时,Lucene会使用你选择的分析器来处理你的文档内容.不同的字段可以使用不同的分析器,所以文档的名称字段可以和汇总字段做不通的分析.也可以不分析字段.

查询时,查询将被分析.但是也可以选择不分析.例如前缀和词查询不被分析,匹配查询被分析.可以在被分析和查询和不被分析查询两者中选择非常有用.例如我么查询LightRed
这个词,标准分析器分析这个查询后,会去查询light和red,如果我们使用不经分析的查询类型,则会明确的查询LightRed这个词.

在索引和查询分析中,索引应该和查询次匹配.如果不匹配,Lucene不会返回所需的文档.例如在建立索引的时候使用了词干提取和小写,那你应该保证查询中的词也必须是词干和小写、
否则,Lucene将不会返回任何结果..重要的是在索引和查询分析时,对所用的标记过滤器保持相同的顺序,这样分析出来的词也是一样的.

### 1.1.3 评分和查询相关性
评分(scoring),是根据文档和查询的匹配度用计分工时计算的结果.默认情况下Lucene使用TF/IDF(term frequency/inverse document frequency, 词频/逆向文档频率)
评分机制.也会有其他评分办法. 评分越高,文档越相关.

## 1.2 ElasticSearch基础

### 1.2.1 数据架构的主要概念

#### 1. 索引
索引(index)是Elasticsearch对逻辑数据的逻辑存储,所以他可以分为更小的部分.可以把索引 看成关系数据库中的表.但是索引中的结果是为了快速有效的全文索引准备的,
它不存储原始值[注意:原书描述是错误的].(默认_source是开启的,存储的是原始值,但是可以关闭)

> 关闭_source影响
> 1. 不能使用_reindex写入新索引 
> 2. 不能使用_update和script update
> 3. 不能使用 _get 或 fields: _source 获取完整文档
> 4. 不能支持高亮（highlight）默认行为
> 5. 无法使用 _source 过滤返回字段
> 6. 不能使用 painless 脚本引用 ctx._source

#### 2. 文档
存储在Elasticsearch中的主要实体叫文档(document) 。类比与关系数据库中的一行记录,在Elasticsearch中,相同的**字段**必须是相同的类型,否则会报错.
> 如果我们不指定字段的类型,那么这个值第一次来的时候会进行推断,作为这个字段的类型,如果后续数据跟当前的不一致的会报错.
> 如果之前没有某个字段,后续插入的时候新出现了字段,默认情况下是会自动推断类型并且不报错的,但是我们关闭了 动态映射关闭（dynamic: false）就会报错
> 一种比较好的习惯是我们主动定义mapping,对于不确定的字段可以使用text或keyword 或者使用dynamic_templates

文档由多个字段组成,每个字段可能多次出现在一个文档中,这样的字段叫**多值字段(multivalued)**.每个字段都有类型,如文本、数值、日期.也可以是复杂类型,
