# 从Druid到ClickHouse | eBay广告平台数据OLAP实战

> **原文**: https://mp.weixin.qq.com/s/AZ1m65voyS6Kvdk7CVNisg  
> **作者**: 吴寒思 周路 余何  
> **发布时间**: 2020-12-11  
> **整理时间**: 2026-02-27  
> **分类**: 后端开发  
> **标签**: Druid、ClickHouse、OLAP、大数据、数据架构

---

## 一句话总结

eBay广告平台从Druid迁移到ClickHouse，介绍了迁移背景、Druid与ClickHouse的对比、迁移原因、系统架构设计、Schema设计优化以及离线数据替换的完整实战经验。

---

## 核心要点

- **数据量大**：每日数百亿条记录，每秒峰值近百万条
- **Druid优势**：组件丰富，数据摄入快，Lambda架构支持
- **ClickHouse优势**：高效压缩(10倍)、向量化引擎、SQL支持、简单架构
- **迁移原因**：运维复杂、延时数据插入限制、主键优化需求
- **关键优化**：表引擎选择、压缩算法、LowCardinality、分区原子替换

---

## 详细内容

### 一、背景

eBay广告数据平台为第一方广告主提供广告流量、用户行为和效果数据分析功能。

**主要挑战：**

| 挑战 | 说明 |
|-----|------|
| 数据量大 | 每日数百亿条记录，每秒峰值近百万条 |
| 离线数据摄入 | 每天对前1-2天数据进行在线替换，需跨节点全局原子操作 |
| 完整性和一致性 | 离线更新后数据不能有遗漏和重复，实时数据延迟需在10秒内 |

---

### 二、Druid VS ClickHouse

#### Druid特点

- 2011年由Metamarkets开发，2015年成为Apache项目
- 为千亿级数据提供亚秒级查询延迟
- 擅长高可用、水平扩展
- 提供丰富的聚合、转换模板，内建多种数据源
- 组件复杂：6种节点类型（Overload, Coordinator, Middle Manager, Indexer, Broker, Historical）
- 依赖MySQL存储元数据、Zookeeper选举、HDFS备份

#### ClickHouse特点

- 由Yandex研发，设计目标是为Yandex.Metrica提供分析报表
- 是一个DBMS，有数据库、表、视图、DDL、DML等完整概念
- 核心特性：
  - **高效存储**：数据压缩率最高10倍
  - **高效查询**：向量化引擎、多处理器并发、分布式查询
  - **灵活接入**：支持SQL、JDBC，与现有数据产品无缝集成

---

### 三、为什么迁移？

#### 3.1 运维

- **Druid**：组件复杂，6种节点类型，依赖MySQL、Zookeeper、HDFS
- **ClickHouse**：对等节点设计，架构简单
- eBay基础架构团队提供定制版ClickHouse服务

#### 3.2 延时数据插入

- Druid：3小时窗口限制，超过无法写入，可能导致数据缺失
- ClickHouse：无限制，任意分区可随时写入

#### 3.3 主键优化

- ClickHouse主键是排序键，允许重复
- 按卖家维度排序，提高查询效率和压缩率

---

### 四、系统架构

系统由4个部分组成：
1. 实时数据获取模块 - 接入eBay行为和交易实时消息平台
2. 离线数据替换模块 - 接入eBay内部数据仓库平台
3. ClickHouse部署和外围数据服务
4. 报表服务 - 支撑广告主、商家后台和eBay公开API

---

### 五、实战经历

#### 5.1 Schema设计

**1）表引擎**

| 数据类型 | 引擎选择 | 原因 |
|---------|---------|------|
| 展示/点击数据 | ReplicatedSummingMergeTree | 数据量大，需汇总降低60%数据量 |
| 销售数据 | ReplicatedMergeTree | 有特殊聚合需求，数据量不大 |

**2）主键**

- SummingMergeTree可单独指定主键
- 排除不需要索引的字段，减小主键大小（主键需全部加载到内存）

**3）压缩算法**

| 算法 | 适用场景 | 压缩效果 |
|-----|---------|---------|
| LZ4 | 默认 | 平衡好 |
| LZ4HC | 非字符串 | 比LZ4节省30%，但插入性能下降60% |
| ZSTD | String类型 | 效果显著 |
| LowCardinality | 低基数字符串 | 额外节省25% |

**组合效果**：LowCardinality + LZ4HC(6) + ZSTD(15) = 原始13%

**4）LowCardinality**

- 对于基数较低的列（列值多样性低）
- 可显著降低原始存储空间

---

#### 5.2 离线数据替换

**挑战：**
- 每日处理近1TB离线数据
- 需要保证原子性和一致性
- 支持大范围数据修正

**数据架构：**
- 采用Lambda架构变体
- ClickHouse分区可单独detach/attach/replace

**Spark聚合与分片：**
- 引入Spark对原始数据进行聚合和分片
- 降低ClickHouse导入压力

**数据更新任务管理：**
1. 锁定分区拓扑结构
2. Spark任务进行数据聚合与分片
3. 数据替换（分区替换方式）

**原子性与一致性：**
- 分区替换：创建临时分区，替换后删除旧分区
- 数据版本：为每条数据引入版本号
- 校验：checksum和行数校验

---

### 六、数据查询

#### 应用架构

- **Internal API**：直接提交线程池执行，需校验过滤非法请求
- **Public API**：异步执行，任务存入DB，定时扫表执行

#### 测试发布

- 数据双写，同时往Druid和ClickHouse写入
- 镜像查询，对比响应验证数据质量和性能
- 灰度发布，逐步切换

#### 查询工具

- Cube.js（二次开发）用于数据可视化

---

### 七、总结

- ClickHouse表现出了良好的性能和扩展能力
- 项目已上线，会持续分享遇到的问题和解决方法

---

## 重点解析

1. **Druid vs ClickHouse的选择**：Druid适合快速开发和数据摄入场景，ClickHouse适合需要强SQL支持和简单运维的场景

2. **压缩与性能的权衡**：高压缩率节省存储但降低插入性能，需要根据业务场景选择

3. **分区原子替换**：通过数据版本机制实现分区级别的原子替换，保证数据一致性

4. **主键优化**：ClickHouse主键是排序键，合理设计可大幅提升查询效率

---

## 个人思考

1. **架构选型需结合团队能力**：eBay有基础架构团队定制ClickHouse，一般团队可能不具备这个条件

2. **数据一致性是核心挑战**：离线数据替换的原子性和一致性保证是迁移成功的关键

3. **Schema设计影响深远**：表引擎、压缩算法、主键设计等对性能和存储有数量级影响，需要反复测试

4. **平滑迁移策略**：双写+灰度发布是保障迁移稳定性的有效手段

---

## 相关文章

- Druid官方文档
- ClickHouse官方文档
- Lambda架构设计模式

---

## 延伸阅读

1. Apache Druid vs ClickHouse: A comparative analysis
2. ClickHouse MergeTree Engine Deep Dive
3. eBay广告数据平台系列文章

---

## 最新研究进展 (2025-2026)

### 1. 大模型(LLM)驱动推荐系统

| 方向 | 说明 |
|-----|------|
| **LLM作为推荐器** | 直接用LLM做推荐（RecGPT、InstructRec） |
| **LLM+协同过滤** | 将LLM语义理解与CF结合 |
| **LLM理解用户偏好** | 用LLM理解用户查询、生成推荐理由 |
| **Rec-R1** | 用强化学习连接LLM与推荐系统 |

### 2. 生成式推荐 (Generative Recommendation)

- **范式转变**：从"判别式"→"生成式"
- 直接生成推荐结果、推荐理由、用户画像
- 2025年有专门Workshop (GenAIRecP 2026 @ WSDM)

### 3. 多模态与长短期偏好

- **层次化长短期偏好建模** (2026.1)
- 层级建模：长期稳定偏好 + 短期动态兴趣
- 结合Transformer捕捉序列模式

### 4. 实时适应与切换机制

- **Switching-based框架** (2026.2, Nature Scientific Reports)
- 根据用户画像动态切换模型
- 解决冷启动、数据稀疏问题

### 5. Agent化推荐系统

- 推荐系统从"工具"→"智能助手/Agent"
- 支持多轮对话、主动询问、推理决策

### 演进对比

| 经典方案 | 2026新进展 |
|---------|-----------|
| 统计/模型方法 | LLM端到端生成 |
| 手工特征工程 | 预训练+微调 |
| 多分类→二分类 | 多模态融合 |
| DIN动态权重 | Agent推理链 |
| 可解释性需求 | 推荐理由生成 |

**核心趋势**：从"特征匹配"向"语义理解+生成式"转变，LLM正在重塑推荐系统范式。

---

*本文档由 Article Saver Skill 自动生成*  
*生成时间: 2026-02-27*
